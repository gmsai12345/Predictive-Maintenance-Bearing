{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaFMlEAYaaoV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'bearing-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F657721%2F1161622%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240411%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240411T100226Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D389268bc322c2f4591ce36da52a604d9610bc74ea014119cded6dd19eff89f8a8c44a20124b4fe14769a0907942a793dce123a23b52796f5c5808dbcbcc9668ece7bffbb36127d440e8d66c13012dca184b8e087631d829df9e2c8ed90f637361f25c99f3ce2dd251e549d40c558b8dd80e41ccceb62db4778808b7b370ec4b2e9a354ee304e1c00fbfde86fddbc159af005895bc67667bd18c958afce19dd1047a8c30426f6faea28d1b9a9d325b6f9d8fcd3d24dcc08813693d8989777a0008761413ffb16fb6cfe2586dbcc8b18ffc7b15aa7a99d000532a17d8d410d238d345f2aa0adf1d0c00e3a1e9e2a8e0726127756a442a9668347c0227315010a80'\n",
        "\n",
        "KAGGLE_INPUT_PATH='content/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='content/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('content/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:22.471438Z",
          "iopub.status.busy": "2021-06-22T07:59:22.471084Z",
          "iopub.status.idle": "2021-06-22T07:59:28.077684Z",
          "shell.execute_reply": "2021-06-22T07:59:28.076555Z",
          "shell.execute_reply.started": "2021-06-22T07:59:22.471404Z"
        },
        "id": "IgOcL7PZaaoW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install hmmlearn -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CFZJXPRaaoW"
      },
      "source": [
        "# About\n",
        "\n",
        "This notebook implements the concept of calculating Remaining Useful Life (RUL) from the NASA bearing dataset. The paper references for implementing the concept are:\n",
        "1. Tobon Mejia, Diego & Medjaher, Kamal & Zerhouni, Noureddine & Tripot, Gerard. (2010). [A Mixture of Gaussians Hidden Markov Model for failure diagnostic and prognostic](https://www.researchgate.net/publication/224177188_A_Mixture_of_Gaussians_Hidden_Markov_Model_for_failure_diagnostic_and_prognostic). 6th Annual IEEE Conference on Automation Science and Engineering, CASE'10.. 338 - 343. 10.1109/COASE.2010.5584759.\n",
        "2. Medjaher, Kamal & Tobon Mejia, Diego & Zerhouni, Noureddine. (2012). [Remaining Useful Life Estimation of Critical Components With Application to Bearings](https://www.researchgate.net/publication/254059871_Remaining_Useful_Life_Estimation_of_Critical_Components_With_Application_to_Bearings). IEEE Transactions on Reliability - TR. 61. 292-302. 10.1109/TR.2012.2194175.\n",
        "3. Tobon Mejia, Diego & Medjaher, Kamal & Zerhouni, Noureddine & Tripot, Gerard. (2012). [A Data-Driven Failure Prognostics Method Based on Mixture of Gaussians Hidden Markov Models](https://www.researchgate.net/publication/254059873_A_Data-Driven_Failure_Prognostics_Method_Based_on_Mixture_of_Gaussians_Hidden_Markov_Models). IEEE Transactions on Reliability - TR. 61. 491-503. 10.1109/TR.2012.2194177."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.080245Z",
          "iopub.status.busy": "2021-06-22T07:59:28.079873Z",
          "iopub.status.idle": "2021-06-22T07:59:28.087638Z",
          "shell.execute_reply": "2021-06-22T07:59:28.08607Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.080208Z"
        },
        "id": "iBYYWEoeaaoW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os, random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "from hmmlearn import hmm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omnN9SvFaaoW"
      },
      "source": [
        "# Description Dataset\n",
        "The data was generated by the NSF I/UCR Center for Intelligent Maintenance Systems (IMS â€“ www.imscenter.net) with support from Rexnord Corp. in Milwaukee, WI.\n",
        "\n",
        "**Test Rig Setup**\n",
        "\n",
        "Four bearings were installed on a shaft. The rotation speed was kept constant at 2000 RPM by an AC motor coupled to the shaft via rub belts. A radial load of 6000 lbs is applied onto the shaft and bearing by a spring mechanism. All bearings are force lubricated. Rexnord ZA-2115 double row bearings were installed on the shaft as shown in Figure 1. PCB 353B33 High Sensitivity Quartz ICP accelerometers were installed on the bearing housing (two accelerometers for each bearing [x- and y-axes] for data set 1, one accelerometer for each bearing for data sets 2 and 3). Sensor placement is also shown in Figure 1. All failures occurred after exceeding designed life time of the bearing which is more than 100 million revolutions.\n",
        "\n",
        "![image.png](attachment:51495a34-c91d-4476-9aae-57525c5d357d.png)]\n",
        "\n",
        "Figure 1 - Bearing Test Rig and sensor placement illustration (Qiu et al., 2006)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3wCiOGiaaoc"
      },
      "source": [
        "**Data Structure**\n",
        "\n",
        "Three (3) data sets are included in the data packet (IMS-Rexnord Bearing Data.zip). Each data set describes a test-to-failure experiment. Each data set consists of individual files that are 1-second vibration signal snapshots recorded at specific intervals. Each file consists of 20,480 points with the sampling rate set at 20 kHz. The file name indicates when the data was collected. Each record (row) in the data file is a data point. Data collection was facilitated by NI DAQ Card 6062E. Larger intervals of time stamps (showed in file names) indicate resumption of the experiment in the next working day.\n",
        "\n",
        "**Set No. 1**\n",
        "\n",
        "| Index                    | Description                                                                                                                   |\n",
        "|--------------------------|-------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Recording Duration:      | October 22, 2003 12:06:24 to November 25, 2003 23:39:56                                                                       |\n",
        "| No. of Files:            | 2,156                                                                                                                         |\n",
        "| No. of Channels:         | 8                                                                                                                             |\n",
        "| Channel Arrangement:     | Bearing 1 â€“ Ch 1&2; Bearing 2 â€“ Ch 3&4; Bearing 3 â€“ Ch 5&6; Bearing 4 â€“ Ch 7&8.                                               |\n",
        "| File Recording Interval: | Every 10 minutes (except the first 43 files were taken every 5 minutes)                                                       |\n",
        "| File Format:             | ASCII                                                                                                                         |\n",
        "| Description:             | At the end of the test-to-failure experiment, inner race defect occurred in bearing 3 and roller element defect in bearing 4. |\n",
        "\n",
        "**Set No. 2**\n",
        "\n",
        "| Index                    | Description                                                                             |\n",
        "|--------------------------|-----------------------------------------------------------------------------------------|\n",
        "| Recording Duration:      | February 12, 2004 10:32:39 to February 19, 2004 06:22:39                                |\n",
        "| No. of Files:            | 984                                                                                     |\n",
        "| No. of Channels:         | 4                                                                                       |\n",
        "| Channel Arrangement:     | Bearing 1 â€“ Ch 1; Bearing2 â€“ Ch 2; Bearing3 â€“ Ch3; Bearing 4 â€“ Ch 4.                    |\n",
        "| File Recording Interval: | Every 10 minutes                                                                        |\n",
        "| File Format:             | ASCII                                                                                   |\n",
        "| Description:             | At the end of the test-to-failure experiment, outer race failure occurred in bearing 1. |\n",
        "\n",
        "**Set No. 3**\n",
        "\n",
        "| Index                    | Description                                                                             |\n",
        "|--------------------------|-----------------------------------------------------------------------------------------|\n",
        "| Recording Duration:      | March 4, 2004 09:27:46 to April 4, 2004 19:01:57                                        |\n",
        "| No. of Files:            | 4,448                                                                                   |\n",
        "| No. of Channels:         | 4                                                                                       |\n",
        "| Channel Arrangement:     | Bearing 1 â€“ Ch 1; Bearing2 â€“ Ch 2; Bearing3 â€“ Ch3; Bearing 4 â€“ Ch 4.                    |\n",
        "| File Recording Interval: | Every 10 minutes                                                                        |\n",
        "| File Format:             | ASCII                                                                                   |\n",
        "| Description:             | At the end of the test-to-failure experiment, outer race failure occurred in bearing 3. |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.090681Z",
          "iopub.status.busy": "2021-06-22T07:59:28.090285Z",
          "iopub.status.idle": "2021-06-22T07:59:28.100555Z",
          "shell.execute_reply": "2021-06-22T07:59:28.099604Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.090647Z"
        },
        "id": "FRSZvWHfaaoc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "SEED = 2021\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJtYEllTaaoc"
      },
      "source": [
        "For feature extraction, you can check this notebook https://www.kaggle.com/yasirabd/nasa-bearing-feature-extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.103213Z",
          "iopub.status.busy": "2021-06-22T07:59:28.10244Z",
          "iopub.status.idle": "2021-06-22T07:59:28.258519Z",
          "shell.execute_reply": "2021-06-22T07:59:28.257794Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.103172Z"
        },
        "id": "NI0ZKZdJaaoc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "set1 = pd.read_csv('../input/nasa-bearing-time-features/set1_timefeatures.csv')\n",
        "set1.columns = ['date'] + list(set1.columns[1:])\n",
        "set1['date'] = pd.to_datetime(set1['date'])\n",
        "\n",
        "set2 = pd.read_csv('../input/nasa-bearing-time-features/set2_timefeatures.csv')\n",
        "set2.columns = ['date'] + list(set2.columns[1:])\n",
        "set2['date'] = pd.to_datetime(set2['date'])\n",
        "\n",
        "set3 = pd.read_csv('../input/nasa-bearing-time-features/set3_timefeatures.csv')\n",
        "set3.columns = ['date'] + list(set3.columns[1:])\n",
        "set3['date'] = pd.to_datetime(set3['date'])\n",
        "\n",
        "# set date as index\n",
        "set1 = set1.set_index('date')\n",
        "set2 = set2.set_index('date')\n",
        "set3 = set3.set_index('date')\n",
        "\n",
        "set1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.259935Z",
          "iopub.status.busy": "2021-06-22T07:59:28.259585Z",
          "iopub.status.idle": "2021-06-22T07:59:28.334864Z",
          "shell.execute_reply": "2021-06-22T07:59:28.334212Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.259907Z"
        },
        "id": "ThmzyE-daaoc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# merge a and b from bearing 1-4\n",
        "set1['B1_mean'] = (set1['B1_a_mean'] + set1['B1_b_mean'])/2\n",
        "set1['B1_std'] = (set1['B1_a_std'] + set1['B1_b_std'])/2\n",
        "set1['B1_skew'] = (set1['B1_a_skew'] + set1['B1_b_skew'])/2\n",
        "set1['B1_kurtosis'] = (set1['B1_a_kurtosis'] + set1['B1_b_kurtosis'])/2\n",
        "set1['B1_entropy'] = (set1['B1_a_entropy'] + set1['B1_b_entropy'])/2\n",
        "set1['B1_rms'] = (set1['B1_a_rms'] + set1['B1_b_rms'])/2\n",
        "set1['B1_max'] = (set1['B1_a_max'] + set1['B1_b_max'])/2\n",
        "set1['B1_p2p'] = (set1['B1_a_p2p'] + set1['B1_b_p2p'])/2\n",
        "\n",
        "set1['B2_mean'] = (set1['B2_a_mean'] + set1['B2_b_mean'])/2\n",
        "set1['B2_std'] = (set1['B2_a_std'] + set1['B2_b_std'])/2\n",
        "set1['B2_skew'] = (set1['B2_a_skew'] + set1['B2_b_skew'])/2\n",
        "set1['B2_kurtosis'] = (set1['B2_a_kurtosis'] + set1['B2_b_kurtosis'])/2\n",
        "set1['B2_entropy'] = (set1['B2_a_entropy'] + set1['B2_b_entropy'])/2\n",
        "set1['B2_rms'] = (set1['B2_a_rms'] + set1['B2_b_rms'])/2\n",
        "set1['B2_max'] = (set1['B2_a_max'] + set1['B2_b_max'])/2\n",
        "set1['B2_p2p'] = (set1['B2_a_p2p'] + set1['B2_b_p2p'])/2\n",
        "\n",
        "set1['B3_mean'] = (set1['B3_a_mean'] + set1['B3_b_mean'])/2\n",
        "set1['B3_std'] = (set1['B3_a_std'] + set1['B3_b_std'])/2\n",
        "set1['B3_skew'] = (set1['B3_a_skew'] + set1['B3_b_skew'])/2\n",
        "set1['B3_kurtosis'] = (set1['B3_a_kurtosis'] + set1['B3_b_kurtosis'])/2\n",
        "set1['B3_entropy'] = (set1['B3_a_entropy'] + set1['B3_b_entropy'])/2\n",
        "set1['B3_rms'] = (set1['B3_a_rms'] + set1['B3_b_rms'])/2\n",
        "set1['B3_max'] = (set1['B3_a_max'] + set1['B3_b_max'])/2\n",
        "set1['B3_p2p'] = (set1['B3_a_p2p'] + set1['B3_b_p2p'])/2\n",
        "\n",
        "set1['B4_mean'] = (set1['B4_a_mean'] + set1['B4_b_mean'])/2\n",
        "set1['B4_std'] = (set1['B4_a_std'] + set1['B4_b_std'])/2\n",
        "set1['B4_skew'] = (set1['B4_a_skew'] + set1['B4_b_skew'])/2\n",
        "set1['B4_kurtosis'] = (set1['B4_a_kurtosis'] + set1['B4_b_kurtosis'])/2\n",
        "set1['B4_entropy'] = (set1['B4_a_entropy'] + set1['B4_b_entropy'])/2\n",
        "set1['B4_rms'] = (set1['B4_a_rms'] + set1['B4_b_rms'])/2\n",
        "set1['B4_max'] = (set1['B4_a_max'] + set1['B4_b_max'])/2\n",
        "set1['B4_p2p'] = (set1['B4_a_p2p'] + set1['B4_b_p2p'])/2\n",
        "\n",
        "set1 = set1[['B1_mean','B1_std','B1_skew','B1_kurtosis','B1_entropy','B1_rms','B1_max','B1_p2p',\n",
        "             'B2_mean','B2_std','B2_skew','B2_kurtosis','B2_entropy','B2_rms','B2_max','B2_p2p',\n",
        "             'B3_mean','B3_std','B3_skew','B3_kurtosis','B3_entropy','B3_rms','B3_max','B3_p2p',\n",
        "             'B4_mean','B4_std','B4_skew','B4_kurtosis','B4_entropy','B4_rms','B4_max','B4_p2p']]\n",
        "set1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdDxau-raaoc"
      },
      "source": [
        "# Slice Features (Mean, RMS, Skewness, Kurtosis)\n",
        "\n",
        "We only used 4 time features: mean, RMS, skewness, and kurtosis.\n",
        "\n",
        "References: (Tobon, 2010) [A mixture of gaussians hidden markov model for failure diagnostic and prognostic.](https://hal.archives-ouvertes.fr/hal-00525073/documenthttps://hal.archives-ouvertes.fr/hal-00525073/document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.336251Z",
          "iopub.status.busy": "2021-06-22T07:59:28.335953Z",
          "iopub.status.idle": "2021-06-22T07:59:28.344327Z",
          "shell.execute_reply": "2021-06-22T07:59:28.343292Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.336223Z"
        },
        "id": "AXkGzdHZaaoc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "cols = ['B1_mean','B1_rms','B1_skew','B1_kurtosis',\n",
        "        'B2_mean','B2_rms','B2_skew','B2_kurtosis',\n",
        "        'B3_mean','B3_rms','B3_skew','B3_kurtosis',\n",
        "        'B4_mean','B4_rms','B4_skew','B4_kurtosis',]\n",
        "set1 = set1[cols]\n",
        "set2 = set2[cols]\n",
        "set3 = set3[cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.346592Z",
          "iopub.status.busy": "2021-06-22T07:59:28.346113Z",
          "iopub.status.idle": "2021-06-22T07:59:28.406069Z",
          "shell.execute_reply": "2021-06-22T07:59:28.405015Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.346549Z"
        },
        "id": "1CTv4kzhaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# statistics\n",
        "set1.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.409518Z",
          "iopub.status.busy": "2021-06-22T07:59:28.409107Z",
          "iopub.status.idle": "2021-06-22T07:59:28.463839Z",
          "shell.execute_reply": "2021-06-22T07:59:28.462851Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.409477Z"
        },
        "id": "SiluijQqaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# statistics\n",
        "set2.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.465759Z",
          "iopub.status.busy": "2021-06-22T07:59:28.465471Z",
          "iopub.status.idle": "2021-06-22T07:59:28.522074Z",
          "shell.execute_reply": "2021-06-22T07:59:28.521129Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.465731Z"
        },
        "id": "lTqSA08iaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# statistics\n",
        "set3.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.523608Z",
          "iopub.status.busy": "2021-06-22T07:59:28.52336Z",
          "iopub.status.idle": "2021-06-22T07:59:28.532934Z",
          "shell.execute_reply": "2021-06-22T07:59:28.531836Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.523583Z"
        },
        "id": "6_BcZlNGaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def plot_features(df):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(15, 5*4))\n",
        "\n",
        "    axes[0].plot(df['B1_mean'])\n",
        "    axes[0].plot(df['B2_mean'])\n",
        "    axes[0].plot(df['B3_mean'])\n",
        "    axes[0].plot(df['B4_mean'])\n",
        "    axes[0].legend(['B1','B2','B3','B4'])\n",
        "    axes[0].set_title('Mean')\n",
        "\n",
        "    axes[1].plot(df['B1_rms'])\n",
        "    axes[1].plot(df['B2_rms'])\n",
        "    axes[1].plot(df['B3_rms'])\n",
        "    axes[1].plot(df['B4_rms'])\n",
        "    axes[1].legend(['B1','B2','B3','B4'])\n",
        "    axes[1].set_title('RMS')\n",
        "\n",
        "    axes[2].plot(df['B1_skew'])\n",
        "    axes[2].plot(df['B2_skew'])\n",
        "    axes[2].plot(df['B3_skew'])\n",
        "    axes[2].plot(df['B4_skew'])\n",
        "    axes[2].legend(['B1','B2','B3','B4'])\n",
        "    axes[2].set_title('Skewness')\n",
        "\n",
        "    axes[3].plot(df['B1_kurtosis'])\n",
        "    axes[3].plot(df['B2_kurtosis'])\n",
        "    axes[3].plot(df['B3_kurtosis'])\n",
        "    axes[3].plot(df['B4_kurtosis'])\n",
        "    axes[3].legend(['B1','B2','B3','B4'])\n",
        "    axes[3].set_title('Kurtosis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:28.534991Z",
          "iopub.status.busy": "2021-06-22T07:59:28.534592Z",
          "iopub.status.idle": "2021-06-22T07:59:29.93307Z",
          "shell.execute_reply": "2021-06-22T07:59:29.932385Z",
          "shell.execute_reply.started": "2021-06-22T07:59:28.534952Z"
        },
        "id": "s8FsB1zWaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# plot set 1\n",
        "plot_features(set1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:29.934405Z",
          "iopub.status.busy": "2021-06-22T07:59:29.934016Z",
          "iopub.status.idle": "2021-06-22T07:59:30.963939Z",
          "shell.execute_reply": "2021-06-22T07:59:30.963027Z",
          "shell.execute_reply.started": "2021-06-22T07:59:29.934365Z"
        },
        "id": "p-FzI1qjaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# plot set 2\n",
        "plot_features(set2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:30.965476Z",
          "iopub.status.busy": "2021-06-22T07:59:30.965222Z",
          "iopub.status.idle": "2021-06-22T07:59:32.142144Z",
          "shell.execute_reply": "2021-06-22T07:59:32.141051Z",
          "shell.execute_reply.started": "2021-06-22T07:59:30.96545Z"
        },
        "id": "Lf175dqEaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# plot set 3\n",
        "plot_features(set3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBQH11vwaaod"
      },
      "source": [
        "# Scaling\n",
        "\n",
        "As mentioned (1), we don't need to perform feature scaling.\n",
        "\n",
        "But, after I did some experiments the result is better with feature scaling.\n",
        "\n",
        "And in hmmlearn library (2), they use KMeans to cluster the number of components in data. Also, KMeans is sensitive with the variance of data, so it is better to perform feature scaling.\n",
        "\n",
        "- (1): https://stats.stackexchange.com/questions/371333/is-it-important-to-make-a-feature-scaling-before-using-gaussian-mixture-model\n",
        "- (2): https://github.com/hmmlearn/hmmlearn/blob/master/lib/hmmlearn/hmm.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:32.143669Z",
          "iopub.status.busy": "2021-06-22T07:59:32.143399Z",
          "iopub.status.idle": "2021-06-22T07:59:32.148678Z",
          "shell.execute_reply": "2021-06-22T07:59:32.14723Z",
          "shell.execute_reply.started": "2021-06-22T07:59:32.143641Z"
        },
        "id": "6JGMGwJlaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def slice_columns(columns, target='B1'):\n",
        "    if target == 'B1':\n",
        "        return columns[0:4]\n",
        "    elif target == 'B2':\n",
        "        return columns[4:8]\n",
        "    elif target == 'B3':\n",
        "        return columns[8:12]\n",
        "    elif target == 'B4':\n",
        "        return columns[12:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:32.150276Z",
          "iopub.status.busy": "2021-06-22T07:59:32.149977Z",
          "iopub.status.idle": "2021-06-22T07:59:32.207961Z",
          "shell.execute_reply": "2021-06-22T07:59:32.206907Z",
          "shell.execute_reply.started": "2021-06-22T07:59:32.150248Z"
        },
        "id": "2axFbeEEaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# with scikit-learn\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "set1_scaled = set1.copy()\n",
        "set2_scaled = set2.copy()\n",
        "set3_scaled = set3.copy()\n",
        "\n",
        "ss_l = []\n",
        "minmax_l = []\n",
        "\n",
        "# scaling set test 1\n",
        "for bear in ['B1','B2','B3','B4']:\n",
        "    col_features = slice_columns(set1.columns, target=bear)\n",
        "    scaler = StandardScaler()\n",
        "#     scaler = MinMaxScaler(feature_range=(-2,2))\n",
        "    set1_scaled[col_features] = scaler.fit_transform(set1[col_features])\n",
        "    ss_l.append(scaler)\n",
        "#     minmax_l.append(scaler)\n",
        "\n",
        "# scaling set test 2\n",
        "for bear in ['B1','B2','B3','B4']:\n",
        "    col_features = slice_columns(set2.columns, target=bear)\n",
        "    scaler = StandardScaler()\n",
        "#     scaler = MinMaxScaler(feature_range=(-2,2))\n",
        "    set2_scaled[col_features] = scaler.fit_transform(set2[col_features])\n",
        "    ss_l.append(scaler)\n",
        "#     minmax_l.append(scaler)\n",
        "\n",
        "# scaling set test 3, except bearing 3\n",
        "for bear in ['B1','B2','B4']:\n",
        "    col_features = slice_columns(set3.columns, target=bear)\n",
        "    scaler = StandardScaler()\n",
        "#     scaler = MinMaxScaler(feature_range=(-2,2))\n",
        "    set3_scaled[col_features] = scaler.fit_transform(set3[col_features])#.round(4)\n",
        "    ss_l.append(scaler)\n",
        "#     minmax_l.append(scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:32.209604Z",
          "iopub.status.busy": "2021-06-22T07:59:32.209337Z",
          "iopub.status.idle": "2021-06-22T07:59:32.737882Z",
          "shell.execute_reply": "2021-06-22T07:59:32.73684Z",
          "shell.execute_reply.started": "2021-06-22T07:59:32.209578Z"
        },
        "id": "N3wsYtXzaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# before and after scaling\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14,5), dpi=80)\n",
        "axes[0].plot(set1['B1_mean'])\n",
        "axes[1].plot(set1_scaled['B1_mean'])\n",
        "\n",
        "axes[0].set_title('Before scaling (Mean)')\n",
        "axes[1].set_title('After scaling (Mean)');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unbC1UX0aaod"
      },
      "source": [
        "# Prepare data\n",
        "\n",
        "- Testing: Set test 3 bearing 3\n",
        "    - 'S3_B3'\n",
        "- Learning: 11 sensor data from each set test\n",
        "    - 'S1_B1','S1_B2','S1_B3','S1_B4',\n",
        "    - 'S2_B1','S2_B2','S2_B3','S2_B4',\n",
        "    - 'S3_B1','S3_B2','S3_B4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Bo3Wsnbaaod"
      },
      "source": [
        "# GMMHMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:32.739328Z",
          "iopub.status.busy": "2021-06-22T07:59:32.739083Z",
          "iopub.status.idle": "2021-06-22T07:59:32.744983Z",
          "shell.execute_reply": "2021-06-22T07:59:32.744046Z",
          "shell.execute_reply.started": "2021-06-22T07:59:32.739303Z"
        },
        "id": "xCTBytSPaaod",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def flip_transmat(tm, ix_sort):\n",
        "    tm_ = tm.copy()\n",
        "    for i,ix in enumerate(ix_sort):\n",
        "        tm_[i, :] = tm[ix[0], :]\n",
        "    tm__ = tm_.copy()\n",
        "    for i,ix in enumerate(ix_sort):\n",
        "        tm__[:, i] = tm_[:,ix[0]]\n",
        "    return tm__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGfihWUmaaod"
      },
      "source": [
        "**How to decide the covariance type?**\n",
        "\n",
        "Covariance matrices for Gaussian Mixture Model has several types such as Full, Tied, Diagonal, and Spherical. You can read more details on this article (1).\n",
        "\n",
        "If we look up into the means of the data features (after scaling) for each state in GMM model, they have close value between each other. So, it is decided that covariance type `tied` has potentital to differentiate between each state. (Still need to understand the concept of this theory)\n",
        "\n",
        "![image.png](attachment:37015e9d-5b95-4acb-9b44-b22fbefbef39.png)\n",
        "\n",
        "\n",
        "- (1) https://stats.stackexchange.com/questions/326671/different-covariance-types-for-gaussian-mixture-models/326678#326678"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRiisJvtaaoe"
      },
      "source": [
        "**How to make a left-right GMMHMM model?**\n",
        "\n",
        "![image.png](attachment:d6863120-2ff8-4c07-a139-be1f0c95cb11.png)\n",
        "\n",
        "Based on references from Sequentia library (1)(2)(3) and hmmlearn library (4), we need to:\n",
        "\n",
        "1. First initiate `start probability` randomly and `transition matrix` with upper right values.\n",
        "2. In GMMHMM model,\n",
        "    - define `init_params` equal `cmw`, means only initialize covariance, means, and weights. Since, we will initiate start probability (`s`) and transition matrix (`t`) manually.\n",
        "    - define `params` equal `stcmw`, means it will update those parameters when training.\n",
        "3. Define `model.startprob_` and `model.transmat_` with its value which has been initialized before.\n",
        "\n",
        "\n",
        "- (1) https://sequentia.readthedocs.io/en/latest/sections/classifiers/gmmhmm.html\n",
        "- (2) https://github.com/eonu/sequentia/blob/master/lib/sequentia/classifiers/hmm/gmmhmm.py\n",
        "- (3) https://github.com/eonu/sequentia/blob/master/lib/sequentia/classifiers/hmm/topologies/left_right.py\n",
        "- (4) https://hmmlearn.readthedocs.io/en/latest/tutorial.html#building-hmm-and-generating-samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyTL2nHPaaoe"
      },
      "source": [
        "Notes:\n",
        "- Still need to modify the model into the left-to-right model. But, somehow when I defined the model as left-to-right, some of the training processes were not successful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:32.746931Z",
          "iopub.status.busy": "2021-06-22T07:59:32.746535Z",
          "iopub.status.idle": "2021-06-22T07:59:32.760747Z",
          "shell.execute_reply": "2021-06-22T07:59:32.759832Z",
          "shell.execute_reply.started": "2021-06-22T07:59:32.74689Z"
        },
        "id": "svDYh94Gaaoe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def random_transitions(n_states) -> np.ndarray:\n",
        "    \"\"\"Sets the transition matrix as random (random probability of transitioning\n",
        "    to all other possible states from each state) by sampling probabilities\n",
        "    from a Dirichlet distribution, according to the topology.\n",
        "    Returns\n",
        "    -------\n",
        "    transitions: :class:`numpy:numpy.ndarray` (float)\n",
        "        The random transition matrix of shape `(n_states, n_states)`.\n",
        "    \"\"\"\n",
        "    transitions = np.zeros((n_states, n_states))\n",
        "    for i, row in enumerate(transitions):\n",
        "        row[i:] = np.random.dirichlet(np.ones(n_states - i))\n",
        "    return transitions\n",
        "\n",
        "def create_gmmhmm():\n",
        "    startprob = np.array([1., 0., 0.], dtype=np.float64)\n",
        "    transmat = np.array([[0.9995, 0.0005,  0.],\n",
        "                         [0.,     0.9998,  0.0002],\n",
        "                         [0.,     0.,      1.0]], dtype=np.float64)\n",
        "#     transmat = np.array([[0.38903512, 0.28715641, 0.32380848],\n",
        "#                          [0.        , 0.56796488, 0.43203512],\n",
        "#                          [0.        , 0.        , 1.        ]], dtype=np.float64)\n",
        "#     transmat = random_transitions(n_states=3)\n",
        "\n",
        "    model = hmm.GMMHMM(n_components=3,\n",
        "                       n_mix=2,\n",
        "                       covariance_type=\"tied\",\n",
        "                       n_iter=1000,\n",
        "                       tol=1e-6,\n",
        "#                        startprob_prior=startprob,\n",
        "#                        transmat_prior=transmat,\n",
        "#                        init_params='cmw',\n",
        "#                        params='stcmw',\n",
        "                       random_state=SEED,\n",
        "                       verbose=False)\n",
        "    model.n_features = 4\n",
        "    model.startprob_ = startprob\n",
        "    model.transmat_ = transmat\n",
        "\n",
        "    return model\n",
        "\n",
        "def fit_gmmhmm(model, data):\n",
        "\n",
        "    # train model\n",
        "    model.fit(data)\n",
        "\n",
        "    # clasify each observation as state (0, 1, 2)\n",
        "    hidden_states = model.predict(data)\n",
        "\n",
        "    # get parameters of GMMHMM\n",
        "    startprob_ = model.startprob_\n",
        "    means_ = model.means_\n",
        "    transmat_ = model.transmat_\n",
        "    covars_ = model.covars_\n",
        "    weights_ = model.weights_\n",
        "\n",
        "    # reorganize by mean, so the the order of the states from lower to higher\n",
        "    ix_sort = np.argsort(np.array([[np.mean(m)] for m in means_]), axis=0)\n",
        "\n",
        "    hidden_states = np.array([ix_sort[st][0] for st in hidden_states])\n",
        "    startprob = np.array([startprob_[ix][0] for ix in ix_sort])\n",
        "    means = np.array([means_[ix][0] for ix in ix_sort])\n",
        "    transmat = flip_transmat(transmat_, ix_sort)\n",
        "    covars = np.array([covars_[ix][0] for ix in ix_sort])\n",
        "    weights = np.array([weights_[ix][0] for ix in ix_sort])\n",
        "\n",
        "    model.startprob_ = startprob\n",
        "    model.means_ = means\n",
        "    model.transmat_ = transmat\n",
        "    model.covars_ = covars\n",
        "    model.weights_ = weights\n",
        "\n",
        "    # logprob\n",
        "    logprob = model.score(data)\n",
        "\n",
        "    return ix_sort, logprob, model, hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:32.761988Z",
          "iopub.status.busy": "2021-06-22T07:59:32.76176Z",
          "iopub.status.idle": "2021-06-22T07:59:32.777657Z",
          "shell.execute_reply": "2021-06-22T07:59:32.776528Z",
          "shell.execute_reply.started": "2021-06-22T07:59:32.761964Z"
        },
        "id": "x7uT1oAUaaoe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def plot_rms_and_state(rms, state):\n",
        "    fig, ax1 = plt.subplots(figsize=(12,5))\n",
        "    ax2 = ax1.twinx()\n",
        "    ax1.plot(rms)\n",
        "    ax1.set_ylabel('RMS')\n",
        "    ax1.set_xlabel('time (minutes)')\n",
        "    ax2.plot(state, color='red')\n",
        "\n",
        "    ax2.set_yticks(range(0,3))\n",
        "    ax2.set_ylabel('state', rotation=270, labelpad=20)\n",
        "    plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:32.779547Z",
          "iopub.status.busy": "2021-06-22T07:59:32.77915Z",
          "iopub.status.idle": "2021-06-22T07:59:36.749341Z",
          "shell.execute_reply": "2021-06-22T07:59:36.748636Z",
          "shell.execute_reply.started": "2021-06-22T07:59:32.779483Z"
        },
        "id": "bqOar9hFaaoe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# example on bearing 1 in the test 1\n",
        "\n",
        "# initialize gmmhmm\n",
        "gmmhmm = create_gmmhmm()\n",
        "\n",
        "# setup data\n",
        "col_features = slice_columns(set1_scaled.columns, target='B1')\n",
        "data = set1_scaled[col_features]\n",
        "\n",
        "# train gmmhmm\n",
        "ix_sort, logprob, model, hidden_states = fit_gmmhmm(gmmhmm, data)\n",
        "\n",
        "print(f'Log probability: {np.around(logprob, decimals=4)}')\n",
        "print(f'Start probability: {np.around(model.startprob_, decimals=4)}')\n",
        "print(f'Means:\\n{np.around(model.means_, decimals=4)}')\n",
        "print(f'Transition Matrix:\\n{np.around(model.transmat_, decimals=3)}')\n",
        "print(f'Covariance matrix:\\n{np.around(model.covars_, decimals=4)}')\n",
        "print(f'Weights:\\n{np.around(model.weights_, decimals=4)}')\n",
        "print(ix_sort)\n",
        "\n",
        "# plot RMS and state\n",
        "plot_rms_and_state(data[data.columns[1]].values, hidden_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd8qBeEqaaoe"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T07:59:36.750969Z",
          "iopub.status.busy": "2021-06-22T07:59:36.750506Z",
          "iopub.status.idle": "2021-06-22T08:00:41.285772Z",
          "shell.execute_reply": "2021-06-22T08:00:41.28481Z",
          "shell.execute_reply.started": "2021-06-22T07:59:36.750937Z"
        },
        "id": "a-GcFTFqaaoe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# model GMMHMM\n",
        "model_gmmhmm = []\n",
        "\n",
        "# train set test 1\n",
        "for bear in ['B1','B2','B3','B4']:\n",
        "    gmmhmm = create_gmmhmm()  # create model\n",
        "    col_features = slice_columns(set1_scaled.columns, target=bear)\n",
        "    ix_sort, logprob, model, hidden_states = fit_gmmhmm(gmmhmm, set1_scaled[col_features])  # train\n",
        "\n",
        "    # append model into list\n",
        "    model_gmmhmm.append((ix_sort, logprob, model, hidden_states))\n",
        "\n",
        "# train set test 2\n",
        "for bear in ['B1','B2','B3','B4']:\n",
        "    gmmhmm = create_gmmhmm()  # create model\n",
        "    col_features = slice_columns(set2_scaled.columns, target=bear)\n",
        "    ix_sort, logprob, model, hidden_states = fit_gmmhmm(gmmhmm, set2_scaled[col_features])  # train\n",
        "\n",
        "    # append model into list\n",
        "    model_gmmhmm.append((ix_sort, logprob, model, hidden_states))\n",
        "\n",
        "# train set test 3, except bearing 3\n",
        "for bear in ['B1','B2','B4']:\n",
        "    gmmhmm = create_gmmhmm()  # create model\n",
        "    col_features = slice_columns(set3_scaled.columns, target=bear)\n",
        "    ix_sort, logprob, model, hidden_states = fit_gmmhmm(gmmhmm, set3_scaled[col_features])  # train\n",
        "\n",
        "    # append model into list\n",
        "    model_gmmhmm.append((ix_sort, logprob, model, hidden_states))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:41.28778Z",
          "iopub.status.busy": "2021-06-22T08:00:41.287249Z",
          "iopub.status.idle": "2021-06-22T08:00:44.421452Z",
          "shell.execute_reply": "2021-06-22T08:00:44.418784Z",
          "shell.execute_reply.started": "2021-06-22T08:00:41.287738Z"
        },
        "id": "mAEkAzXeaaoe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# get rms data for each bearing test, except set test 3 bearing 3 (S3_B3) because test set\n",
        "rms_data = []\n",
        "for bear in ['B1','B2','B3','B4']:\n",
        "    col_features = slice_columns(set1_scaled.columns, target=bear)\n",
        "    data = set1[col_features]\n",
        "    rms = data[data.columns[1]]\n",
        "    rms_data.append(rms)\n",
        "for bear in ['B1','B2','B3','B4']:\n",
        "    col_features = slice_columns(set2_scaled.columns, target=bear)\n",
        "    data = set2[col_features]\n",
        "    rms = data[data.columns[1]]\n",
        "    rms_data.append(rms)\n",
        "for bear in ['B1','B2','B4']:\n",
        "    col_features = slice_columns(set3_scaled.columns, target=bear)\n",
        "    data = set3[col_features]\n",
        "    rms = data[data.columns[1]]\n",
        "    rms_data.append(rms)\n",
        "\n",
        "# sequence data for training\n",
        "model_data = ['S1_B1','S1_B2','S1_B3','S1_B4',\n",
        "              'S2_B1','S2_B2','S2_B3','S2_B4',\n",
        "              'S3_B1','S3_B2','S3_B4']\n",
        "\n",
        "for (ix_sort,logprob,model,hidden_states),data,rms in zip(model_gmmhmm, model_data, rms_data):\n",
        "    print(f'Sequence data: {data}')\n",
        "    print(f'Logprob\\n {np.around(logprob, decimals=4)}')\n",
        "    print(f'Start Probability {np.around(model.startprob_, decimals=4)}')\n",
        "    print(f'Means\\n {np.around(model.means_, decimals=4)}')\n",
        "    print(f'Transition Matrix\\n {np.around(model.transmat_, decimals=3)}')\n",
        "    print(f'Mixture Weights\\n {np.around(model.weights_, decimals=4)}')\n",
        "    print(f'Covariance matrix:\\n{np.around(model.covars_, decimals=4)}')\n",
        "\n",
        "    # plot RMS and state\n",
        "    plot_rms_and_state(rms.values, hidden_states)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oa13wkCaaoe"
      },
      "source": [
        "## Testing (S3_B3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:44.424995Z",
          "iopub.status.busy": "2021-06-22T08:00:44.424729Z",
          "iopub.status.idle": "2021-06-22T08:00:48.491859Z",
          "shell.execute_reply": "2021-06-22T08:00:48.490648Z",
          "shell.execute_reply.started": "2021-06-22T08:00:44.424969Z"
        },
        "id": "IyGZDUffaaoe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# logprob and plot decode state on S3_B3\n",
        "logprob_l = []\n",
        "i = 0\n",
        "for (ix,logprob,model,hidden_states),data in zip(model_gmmhmm, model_data):\n",
        "    # select features\n",
        "    col_features = slice_columns(set3.columns, target='B3')\n",
        "\n",
        "    # scaling\n",
        "    S3_B3 = ss_l[i].transform(set3[col_features])\n",
        "    i += 1\n",
        "\n",
        "    # calculate logprob on model sample\n",
        "    logprob = model.score(S3_B3)\n",
        "    pred = model.predict(S3_B3)\n",
        "\n",
        "    logprob_l.append(logprob)\n",
        "\n",
        "    print(f'GMMHMM model from {data} got log probability on S3_B3: {logprob}')\n",
        "    rms = set3[col_features]['B3_rms']\n",
        "\n",
        "    # plot RMS and decode state\n",
        "    plot_rms_and_state(rms.values, pred)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mzpxvdoaaoe"
      },
      "source": [
        "**How to interpret log probability?**\n",
        "\n",
        "From reference (1), the more negative value of log probability, the better performance of the model. It happens because if we do exponentials of the log probability on the most negative log prob, the result will more close to zero.\n",
        "\n",
        "But, if we see the decoding state of all the models, the result is not as expected from the theory. Theoretically, the GMMHMM model from `S1_B1` with log prob -21625910.26 is the best among others. But, the models from `S1_B4`, `S2_B1`, and `S3_B1` have better results on decoding states despite their log prob respectively got -428826.79, -44063.25, -106197.6555733793.\n",
        "\n",
        "- (1) https://www.mathworks.com/matlabcentral/answers/351766-how-to-interpret-log-probability-from-hmmdecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.494014Z",
          "iopub.status.busy": "2021-06-22T08:00:48.493712Z",
          "iopub.status.idle": "2021-06-22T08:00:48.500399Z",
          "shell.execute_reply": "2021-06-22T08:00:48.49927Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.493977Z"
        },
        "id": "3Xrr1sFjaaoe",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# example exponential on negative log probability\n",
        "np.exp(-100), np.exp(-150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZoyUPFvaaof"
      },
      "source": [
        "**What is the best model chosen?**\n",
        "\n",
        "Comparing the result above, model from `S2_B1` is the best on predicting/decoding state of test data `S3_B3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.502358Z",
          "iopub.status.busy": "2021-06-22T08:00:48.502006Z",
          "iopub.status.idle": "2021-06-22T08:00:48.538215Z",
          "shell.execute_reply": "2021-06-22T08:00:48.537146Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.502325Z"
        },
        "id": "AlzrOqJ4aaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# index best model\n",
        "i = 4\n",
        "\n",
        "# select best model\n",
        "ix, logprob, model, hidden_states = model_gmmhmm[i]\n",
        "\n",
        "# transform data\n",
        "S3_B3 = ss_l[i].transform(set3[col_features])\n",
        "model.score(S3_B3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AozBYSDcaaof"
      },
      "source": [
        "# Remaining Useful Life (RUL)\n",
        "\n",
        "Based on reference (1), the formula to calculate mean and standard deviation are:\n",
        "\n",
        "$$\\mu(D(S_i)) = \\frac{\\sum_{w = 1}^{\\Omega} D(S_{iw})}{\\Omega}$$\n",
        "\n",
        "$$\\sigma(D(S_i)) = \\frac{\\sum_{w = 1}^{\\Omega} [D(S_{iw})- \\mu(D(S_i))]^2}{\\Omega}$$\n",
        "\n",
        "where,\n",
        "- $D(.)$ is visit duration\n",
        "- $i$ is the state index\n",
        "- $w$ is the visit index\n",
        "- $\\Omega$ is the total of visits\n",
        "\n",
        "The formula to calculate RUL with $\\eta$ is confidence value:\n",
        "\n",
        "$$RUL_{upper} = \\sum_{i = current state}^{N} [\\mu(D(S_{i})) + \\eta.\\sigma(D(S_i))]$$\n",
        "\n",
        "$$RUL_{mean} = \\sum_{i = current state}^{N} \\mu(D(S_{i}))$$\n",
        "\n",
        "$$RUL_{lower} = \\sum_{i = current state}^{N} [\\mu(D(S_{i})) - \\eta.\\sigma(D(S_i))]$$\n",
        "\n",
        "- (1) Tobon Mejia, Diego & Medjaher, Kamal & Zerhouni, Noureddine & Tripot, Gerard. (2010). [A Mixture of Gaussians Hidden Markov Model for failure diagnostic and prognostic](https://www.researchgate.net/publication/224177188_A_Mixture_of_Gaussians_Hidden_Markov_Model_for_failure_diagnostic_and_prognostic). 6th Annual IEEE Conference on Automation Science and Engineering, CASE'10.. 338 - 343. 10.1109/COASE.2010.5584759."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHN3Gdipaaof"
      },
      "source": [
        "To align the formula and the code, I will try to implement figure of decoding state from set test 1 bearing from reference (1) above.\n",
        "![image.png](attachment:beb76006-5643-49e1-bd94-16495e369588.png)\n",
        "\n",
        "After did subtitution, we got duration for each state index.\n",
        "![e952fec8-bf58-4cbb-b50e-488bd79e9b07.jfif](attachment:faabc8f9-effc-4f65-9e7f-71792a877194.jfif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.540524Z",
          "iopub.status.busy": "2021-06-22T08:00:48.539855Z",
          "iopub.status.idle": "2021-06-22T08:00:48.548356Z",
          "shell.execute_reply": "2021-06-22T08:00:48.546983Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.540473Z"
        },
        "id": "OQG5Idx-aaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def calculate_mean(durations):\n",
        "    return np.mean(durations)\n",
        "\n",
        "def calculate_std(durations):\n",
        "    return np.std(durations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.552083Z",
          "iopub.status.busy": "2021-06-22T08:00:48.549987Z",
          "iopub.status.idle": "2021-06-22T08:00:48.5645Z",
          "shell.execute_reply": "2021-06-22T08:00:48.563077Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.552009Z"
        },
        "id": "l0lWcZrxaaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "D_S1 = [0.458, 0.286]\n",
        "D_S2 = [0.393, 0.334]\n",
        "D_S3 = [0.357, 0.328]\n",
        "\n",
        "print(f\"S1 = [mean(S1), std(S1)] = [{math.floor(calculate_mean(D_S1)*10000)}, {math.floor(calculate_std(D_S1)*10000)}]\")\n",
        "print(f\"S2 = [mean(S2), std(S2)] = [{math.floor(calculate_mean(D_S2)*10000)}, {math.floor(calculate_std(D_S2)*10000)}]\")\n",
        "print(f\"S3 = [mean(S3), std(S3)] = [{math.floor(calculate_mean(D_S3)*10000)}, {math.ceil(calculate_std(D_S3)*10000)}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE1brym0aaof"
      },
      "source": [
        "The result is the same with the paper, so the code implemented is proven.\n",
        "\n",
        "![image.png](attachment:a9af1e20-1591-4622-9d72-b66cd1721cd1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRrnOaRyaaof"
      },
      "source": [
        "After we've found mean and standard deviation for each state, we can calculate RUL from the formula above.\n",
        "\n",
        "The path estimation of the example on set test 1 bearing 1 above like this\n",
        "\n",
        "```\n",
        "S2 -> S1 -> S2 -> S3 -> S1 -> S3\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.567213Z",
          "iopub.status.busy": "2021-06-22T08:00:48.566471Z",
          "iopub.status.idle": "2021-06-22T08:00:48.578972Z",
          "shell.execute_reply": "2021-06-22T08:00:48.577919Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.567157Z"
        },
        "id": "DaVAUZCgaaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "result = {'S1': {'mean': int(calculate_mean(D_S1)*10000),\n",
        "                 'std': int(calculate_std(D_S1)*10000)},\n",
        "          'S2': {'mean': int(calculate_mean(D_S2)*10000),\n",
        "                 'std': int(calculate_std(D_S2)*10000)},\n",
        "          'S3': {'mean': int(calculate_mean(D_S3)*10000),\n",
        "                 'std': math.ceil(calculate_std(D_S3)*10000)}\n",
        "         }\n",
        "path = ['S2','S1','S2','S3','S1','S3']\n",
        "\n",
        "result, path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.581201Z",
          "iopub.status.busy": "2021-06-22T08:00:48.580587Z",
          "iopub.status.idle": "2021-06-22T08:00:48.59684Z",
          "shell.execute_reply": "2021-06-22T08:00:48.595581Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.581153Z"
        },
        "id": "rNY0Q0e4aaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def calculate_rul(path, result, conf=0.95):\n",
        "    rul = []\n",
        "\n",
        "    cum_rul = 0\n",
        "    for p in path:\n",
        "        if p == 'S1':\n",
        "            rul_upper = result.get('S1').get('mean') + conf * result.get('S1').get('std') + cum_rul\n",
        "            rul_mean = result.get('S1').get('mean') + cum_rul\n",
        "            rul_lower = result.get('S1').get('mean') - conf * result.get('S1').get('std') + cum_rul\n",
        "\n",
        "            cum_rul += result.get('S1').get('mean')\n",
        "        elif p == 'S2':\n",
        "            rul_upper = result.get('S2').get('mean') + conf * result.get('S2').get('std') + cum_rul\n",
        "            rul_mean = result.get('S2').get('mean') + cum_rul\n",
        "            rul_lower = result.get('S2').get('mean') - conf * result.get('S2').get('std') + cum_rul\n",
        "\n",
        "            cum_rul += result.get('S2').get('mean')\n",
        "        elif p == 'S3':\n",
        "            rul_upper = result.get('S3').get('mean') + conf * result.get('S3').get('std') + cum_rul\n",
        "            rul_mean = result.get('S3').get('mean') + cum_rul\n",
        "            rul_lower = result.get('S3').get('mean') - conf * result.get('S3').get('std') + cum_rul\n",
        "\n",
        "            cum_rul += result.get('S3').get('mean')\n",
        "\n",
        "        rul.append((rul_upper, rul_mean, rul_lower))\n",
        "    return rul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.599091Z",
          "iopub.status.busy": "2021-06-22T08:00:48.598438Z",
          "iopub.status.idle": "2021-06-22T08:00:48.612967Z",
          "shell.execute_reply": "2021-06-22T08:00:48.611955Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.599021Z"
        },
        "id": "AUztUAB8aaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "calculate_rul(path, result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.615153Z",
          "iopub.status.busy": "2021-06-22T08:00:48.614537Z",
          "iopub.status.idle": "2021-06-22T08:00:48.622361Z",
          "shell.execute_reply": "2021-06-22T08:00:48.621477Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.615105Z"
        },
        "id": "1V38BWumaaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "range_index = [(0, 3930), (3930, 8510), (8510, 11850), (11850, 15420), (15420, 18280), (18280, 21560)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.624393Z",
          "iopub.status.busy": "2021-06-22T08:00:48.623811Z",
          "iopub.status.idle": "2021-06-22T08:00:48.67184Z",
          "shell.execute_reply": "2021-06-22T08:00:48.670722Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.624353Z"
        },
        "id": "XYimbM5xaaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_visual = pd.DataFrame()\n",
        "df_visual['index'] = [i for i in range(0,21560,10)]\n",
        "df_visual['state'] = [1]*393 + [0]*458 + [1]*334 + [2]*357 + [0]*286 + [2]*328\n",
        "df_visual['rul_upper'] = [3915.25]*393 + [8172.0]*458 + [11270.25]*334 + [14552.75]*357 + [18952.0]*286 + [21697.75]*328\n",
        "df_visual['rul_mean'] = [3635]*393 + [7355]*458 + [10990]*334 + [14415]*357 + [18135]*286 + [21560]*328\n",
        "df_visual['rul_lower'] = [3354.75]*393 + [6538]*458 + [10709.75]*334 + [14277.25]*357 + [17318]*286 + [21422.25]*328\n",
        "df_visual['rul_error_upper'] = (21560 - df_visual['rul_upper'])/21560 * 100\n",
        "df_visual['rul_error_mean'] = (21560 - df_visual['rul_mean'])/21560 * 100\n",
        "df_visual['rul_error_lower'] = (21560 - df_visual['rul_lower'])/21560 * 100\n",
        "\n",
        "df_visual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.674168Z",
          "iopub.status.busy": "2021-06-22T08:00:48.673499Z",
          "iopub.status.idle": "2021-06-22T08:00:48.828623Z",
          "shell.execute_reply": "2021-06-22T08:00:48.827551Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.674116Z"
        },
        "id": "VcXLGovPaaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# hidden state\n",
        "plt.figure(figsize=(12,5), dpi=80)\n",
        "plt.plot(df_visual['index'], df_visual['state'])\n",
        "plt.yticks(range(0,3));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:48.830356Z",
          "iopub.status.busy": "2021-06-22T08:00:48.82998Z",
          "iopub.status.idle": "2021-06-22T08:00:49.096002Z",
          "shell.execute_reply": "2021-06-22T08:00:49.095222Z",
          "shell.execute_reply.started": "2021-06-22T08:00:48.830319Z"
        },
        "id": "Qf1d2LQSaaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# RUL estimation\n",
        "plt.figure(figsize=(12,8), dpi=80)\n",
        "plt.plot(df_visual['index'], [21560]*2156, color='r', linestyle='--')\n",
        "plt.plot(df_visual['index'], df_visual['rul_upper'], linestyle='--')\n",
        "plt.plot(df_visual['index'], df_visual['rul_mean'])\n",
        "plt.plot(df_visual['index'], df_visual['rul_lower'], linestyle='--')\n",
        "\n",
        "plt.legend(['Real','RUL Upper', 'RUL Mean', 'RUL Lower'])\n",
        "plt.ylabel('Failure time (min)')\n",
        "plt.xlabel('Current time (min)');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.09785Z",
          "iopub.status.busy": "2021-06-22T08:00:49.097346Z",
          "iopub.status.idle": "2021-06-22T08:00:49.302315Z",
          "shell.execute_reply": "2021-06-22T08:00:49.301688Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.097813Z"
        },
        "id": "MYBAdeTvaaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# RUL error associated\n",
        "plt.figure(figsize=(12,8), dpi=80)\n",
        "plt.plot(df_visual['index'], df_visual['rul_error_upper'], linestyle='--')\n",
        "plt.plot(df_visual['index'], df_visual['rul_error_mean'])\n",
        "plt.plot(df_visual['index'], df_visual['rul_error_lower'], linestyle='--')\n",
        "\n",
        "plt.legend(['RUL Upper', 'RUL Mean', 'RUL Lower'])\n",
        "plt.ylabel('Error (%)')\n",
        "plt.xlabel('Current time (min)');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.303914Z",
          "iopub.status.busy": "2021-06-22T08:00:49.303478Z",
          "iopub.status.idle": "2021-06-22T08:00:49.306472Z",
          "shell.execute_reply": "2021-06-22T08:00:49.305912Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.303884Z"
        },
        "id": "qFQtRSTEaaof",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# def rul2(time_state, conf_score):\n",
        "#     mean = {0: [], 1: [], 2: []}\n",
        "#     std = {0: [], 1: [], 2: []}\n",
        "\n",
        "#     for data in time_state.items():\n",
        "#         print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.307944Z",
          "iopub.status.busy": "2021-06-22T08:00:49.307518Z",
          "iopub.status.idle": "2021-06-22T08:00:49.319308Z",
          "shell.execute_reply": "2021-06-22T08:00:49.318567Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.307915Z"
        },
        "id": "xkYmQir_aaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # function calculate RUL\n",
        "# def rul(time_state, conf):\n",
        "#     # calculate mean and standard deviation\n",
        "#     mean_std = {0: [], 1: [], 2: []}\n",
        "#     for data in time_state.items():\n",
        "#         state, time = data[0], data[1]\n",
        "\n",
        "#         decrease_time = []\n",
        "#         if time:\n",
        "#             for t in time:\n",
        "#                 decrease_time.append(t[1]-t[0])\n",
        "\n",
        "#         mean_state = np.mean(decrease_time)\n",
        "#         std_state = np.std(decrease_time)\n",
        "\n",
        "#         mean_std[state].append((mean_state, std_state))\n",
        "\n",
        "\n",
        "\n",
        "#     # convert nan to zero\n",
        "#     mean_std[0][0], mean_std[1][0], mean_std[2][0] = np.nan_to_num(mean_std[0][0]), np.nan_to_num(mean_std[1][0]), np.nan_to_num(mean_std[2][0])\n",
        "\n",
        "#     # rul upper\n",
        "#     rul_upper = (mean_std[0][0][0] + conf * mean_std[0][0][1]) + \\\n",
        "#                 (mean_std[1][0][0] + conf * mean_std[1][0][1]) + \\\n",
        "#                 (mean_std[2][0][0] + conf * mean_std[2][0][1])\n",
        "\n",
        "#     # RUL Mean\n",
        "#     rul_mean = (mean_std[0][0][0]) + \\\n",
        "#                (mean_std[1][0][0]) + \\\n",
        "#                (mean_std[2][0][0])\n",
        "\n",
        "#     # RUL lower\n",
        "#     rul_lower = (mean_std[0][0][0] - conf * mean_std[0][0][1]) + \\\n",
        "#                 (mean_std[1][0][0] - conf * mean_std[1][0][1]) + \\\n",
        "#                 (mean_std[2][0][0] - conf * mean_std[2][0][1])\n",
        "#     # print(mean_std)\n",
        "#     return rul_upper, rul_mean, rul_lower"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.320841Z",
          "iopub.status.busy": "2021-06-22T08:00:49.320445Z",
          "iopub.status.idle": "2021-06-22T08:00:49.332911Z",
          "shell.execute_reply": "2021-06-22T08:00:49.332256Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.320802Z"
        },
        "id": "3oo9InWqaaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # model terbaik dari S3_B1\n",
        "# col_features = slice_columns(set3.columns, target='B3')\n",
        "# S3_B3 = minmax_l[0].transform(set3[col_features])\n",
        "\n",
        "# # ambil model S3_B1\n",
        "# gmmhmm = model_gmmhmm[0][2]\n",
        "\n",
        "# x = range(len(S3_B3))\n",
        "# y = gmmhmm.predict(S3_B3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.334349Z",
          "iopub.status.busy": "2021-06-22T08:00:49.333944Z",
          "iopub.status.idle": "2021-06-22T08:00:49.34685Z",
          "shell.execute_reply": "2021-06-22T08:00:49.345951Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.334312Z"
        },
        "id": "b8lonxBlaaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# gmmhmm.transmat_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.348199Z",
          "iopub.status.busy": "2021-06-22T08:00:49.34792Z",
          "iopub.status.idle": "2021-06-22T08:00:49.357831Z",
          "shell.execute_reply": "2021-06-22T08:00:49.356904Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.348172Z"
        },
        "id": "IRkvVlriaaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # slicing only for experiment\n",
        "# x_ = range(len(S3_B3))[:150]\n",
        "# y_ = gmmhmm.predict(S3_B3)[:150]\n",
        "# y_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.359761Z",
          "iopub.status.busy": "2021-06-22T08:00:49.359239Z",
          "iopub.status.idle": "2021-06-22T08:00:49.371159Z",
          "shell.execute_reply": "2021-06-22T08:00:49.370014Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.359722Z"
        },
        "id": "DFfPpABCaaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# # calculate RUL\n",
        "# time_state = {0: [], 1: [], 2: []}\n",
        "# state_rul = []\n",
        "# time_rul = []\n",
        "\n",
        "# previous = None\n",
        "# start_time = 0\n",
        "\n",
        "# i = 0\n",
        "# for time_x, state_y in zip(x, y):\n",
        "#     # initiate start time and state\n",
        "#     if previous is None:\n",
        "#         previous = state_y\n",
        "#         start_time = time_x\n",
        "\n",
        "#     # if previous state different with next state, calculate time\n",
        "#     if previous != state_y:\n",
        "#         time_state[previous].append((start_time, time_x))\n",
        "#         start_time = time_x\n",
        "#         rul_upper, rul_mean, rul_lower = rul(time_state, 0.95)\n",
        "\n",
        "# #         print(time_state)\n",
        "# #         print(f'RUL UPPER: {rul_upper}; RUL MEAN: {rul_mean}; RUL LOWER: {rul_lower}')\n",
        "# #         print()\n",
        "\n",
        "#         state_rul.append((rul_upper, rul_mean, rul_lower))\n",
        "#         time_rul.append([time_x, rul_upper, rul_mean, rul_lower])\n",
        "\n",
        "#     previous = state_y\n",
        "\n",
        "#     # if time_x equals last time in index\n",
        "#     if time_x == x[-1]:\n",
        "#         time_state[previous].append((start_time, time_x))\n",
        "#         rul_upper, rul_mean, rul_lower = rul(time_state, 0.95)\n",
        "#         state_rul.append((rul_upper, rul_mean, rul_lower))\n",
        "#         time_rul.append([time_x, rul_upper, rul_mean, rul_lower])\n",
        "# # time_rul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.373437Z",
          "iopub.status.busy": "2021-06-22T08:00:49.372954Z",
          "iopub.status.idle": "2021-06-22T08:00:49.385004Z",
          "shell.execute_reply": "2021-06-22T08:00:49.384177Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.373396Z"
        },
        "id": "rjf3C625aaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# df_rul = pd.DataFrame(data={'RUL UPPER': [], 'RUL MEAN': [], 'RUL LOWER': []})\n",
        "# for data in state_rul:\n",
        "#     df_rul = df_rul.append({'RUL UPPER': data[0], 'RUL MEAN': data[1], 'RUL LOWER': data[2]}, ignore_index=True)\n",
        "# df_rul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.386763Z",
          "iopub.status.busy": "2021-06-22T08:00:49.386218Z",
          "iopub.status.idle": "2021-06-22T08:00:49.397815Z",
          "shell.execute_reply": "2021-06-22T08:00:49.396677Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.386721Z"
        },
        "id": "Ki6xcb6iaaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# df_time_rul = pd.DataFrame(time_rul, columns=['time', 'rul_upper', 'rul_mean', 'rul_lower'])\n",
        "# df_time_rul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.399746Z",
          "iopub.status.busy": "2021-06-22T08:00:49.399352Z",
          "iopub.status.idle": "2021-06-22T08:00:49.409376Z",
          "shell.execute_reply": "2021-06-22T08:00:49.408432Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.399704Z"
        },
        "id": "eEjVI8kYaaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# df_visualize_rul = pd.DataFrame({\"time\": [], \"rul_upper\": [], \"rul_mean\": [], \"rul_lower\": []})\n",
        "\n",
        "# for index, data in df_time_rul.iterrows():\n",
        "#     # if last index\n",
        "#     if index == df_time_rul.shape[0]-1:\n",
        "#         df_visualize_rul = df_visualize_rul.append({\"time\": data[\"time\"], \"rul_upper\": data[\"rul_upper\"], \"rul_mean\": data[\"rul_mean\"], \"rul_lower\": data[\"rul_lower\"]}, ignore_index=True)\n",
        "#     else:\n",
        "#         # check time for next index, if difference not 10, do something\n",
        "#         current_time = data[\"time\"]\n",
        "#         next_time = df_time_rul.iloc[index+1][\"time\"]\n",
        "#         if next_time - current_time > 10:\n",
        "#             while next_time > current_time:\n",
        "#                 df_visualize_rul = df_visualize_rul.append({\"time\": int(current_time), \"rul_upper\": data[\"rul_upper\"], \"rul_mean\": data[\"rul_mean\"], \"rul_lower\": data[\"rul_lower\"]}, ignore_index=True)\n",
        "#                 current_time += 10\n",
        "#         else:\n",
        "#             df_visualize_rul = df_visualize_rul.append({\"time\": int(current_time), \"rul_upper\": data[\"rul_upper\"], \"rul_mean\": data[\"rul_mean\"], \"rul_lower\": data[\"rul_lower\"]}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.410774Z",
          "iopub.status.busy": "2021-06-22T08:00:49.410519Z",
          "iopub.status.idle": "2021-06-22T08:00:49.426151Z",
          "shell.execute_reply": "2021-06-22T08:00:49.425128Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.410749Z"
        },
        "id": "-OuYxXHEaaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# df_visualize_rul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-22T08:00:49.427429Z",
          "iopub.status.busy": "2021-06-22T08:00:49.427181Z",
          "iopub.status.idle": "2021-06-22T08:00:49.438012Z",
          "shell.execute_reply": "2021-06-22T08:00:49.436889Z",
          "shell.execute_reply.started": "2021-06-22T08:00:49.427404Z"
        },
        "id": "IA2uCqKLaaog",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(12,5), dpi=80)\n",
        "# plt.plot(df_visualize_rul[\"time\"], df_visualize_rul[\"rul_upper\"])\n",
        "# plt.plot(df_visualize_rul[\"time\"], df_visualize_rul[\"rul_mean\"])\n",
        "# plt.plot(df_visualize_rul[\"time\"], df_visualize_rul[\"rul_lower\"])\n",
        "\n",
        "# plt.title(\"Grafik Remaining Useful Life (RUL)\", fontsize=20)\n",
        "# plt.ylabel(\"Remaining Useful Life (RUL)\", fontsize=16)\n",
        "# plt.xlabel(\"Waktu (Menit)\", fontsize=18)\n",
        "# plt.legend(['RUL UPPER', 'RUL MEAN', 'RUL LOWER'], loc='upper left')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-886oGDYaaog"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "RUL NASA Bearing (Mean, RMS, Skewness, Kurtosis)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
